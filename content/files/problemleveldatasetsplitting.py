# -*- coding: utf-8 -*-
"""ProblemLevelDatasetSplitting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQDNpl6P_Aqjcv7zyHqP8Yxx5W9Uf5ha

# Problem Level Dataset Splitting - Prevents Data Leakage
"""

!pip install javalang

import json
import javalang

# =========================================
# CONFIG
# =========================================
INPUT_FILE = "/content/datasets/codenet_combined_translator_dataset.jsonl"
OUTPUT_FILE = "/content/datasets/codenet_combined_translator_dataset_astfixed.jsonl"

# =========================================
# JAVA AST PARSABILITY CHECK
# =========================================
def java_ast_parsable(code):
    try:
        javalang.parse.parse(code)
        return True
    except Exception:
        return False

# =========================================
# GET JAVA TRANSLATION BASED ON TEACHER
# =========================================
def get_reference_java(obj):
    teacher = obj.get("teacher")

    if teacher == "StarCoder":
        return obj.get("translated_java_code")

    if teacher == "QwenCoder":
        return obj.get("qwencoder_translation_clean")

    if teacher == "DeepSeekCoder":
        return obj.get("deepseekcoder_translation_clean")

    return None

# =========================================
# PROCESS FILE
# =========================================
total = 0
checked = 0
downgraded = 0
kept = 0

with open(INPUT_FILE, "r", encoding="utf-8") as fin, \
     open(OUTPUT_FILE, "w", encoding="utf-8") as fout:

    for line in fin:
        obj = json.loads(line)
        total += 1

        # Only re-evaluate score == 1
        if obj.get("score") == 1:
            checked += 1
            java_code = get_reference_java(obj)

            # If no code or not AST-parsable → downgrade
            if not java_code or not java_code.strip() or not java_ast_parsable(java_code):
                obj["score"] = 0
                downgraded += 1
            else:
                kept += 1

        fout.write(json.dumps(obj) + "\n")

# =========================================
# SUMMARY
# =========================================
print("=========================================")
print("AST-BASED PARSABILITY FIX (score == 1)")
print("=========================================")
print(f"Total instances        : {total}")
print(f"Score==1 checked       : {checked}")
print(f"Kept as score==1       : {kept}")
print(f"Downgraded to score==0: {downgraded}")
print(f"Output written to      : {OUTPUT_FILE}")

import json
import os
import tempfile

# =========================================
# CONFIG
# =========================================
FILE_PATH = "/content/datasets/codenet_combined_translator_dataset_astfixed.jsonl"

# =========================================
# IN-PLACE FILTERING (SAFE)
# =========================================
total = 0
removed = 0
kept = 0

dir_name = os.path.dirname(FILE_PATH)
tmp_fd, tmp_path = tempfile.mkstemp(dir=dir_name, suffix=".jsonl")

with os.fdopen(tmp_fd, "w", encoding="utf-8") as fout, \
     open(FILE_PATH, "r", encoding="utf-8") as fin:

    for line in fin:
        obj = json.loads(line)
        total += 1

        if obj.get("score") == 0:
            removed += 1
            continue

        fout.write(json.dumps(obj, ensure_ascii=False) + "\n")
        kept += 1

# Replace original file atomically
os.replace(tmp_path, FILE_PATH)

# =========================================
# SUMMARY
# =========================================
print("=========================================")
print("IN-PLACE REMOVAL OF SCORE == 0")
print("=========================================")
print(f"File updated           : {FILE_PATH}")
print(f"Total instances read   : {total}")
print(f"Removed (score == 0)   : {removed}")
print(f"Kept (score >= 1)      : {kept}")

import json
from collections import defaultdict, Counter

# =====================================================
# CONFIG
# =====================================================
INPUT_FILE = "/content/datasets/codenet_combined_translator_dataset_astfixed.jsonl"

# =====================================================
# LOAD DATA
# =====================================================
samples = []
problem_ids = set()
split_problems = defaultdict(set)

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    for line in f:
        item = json.loads(line)
        samples.append(item)
        pid = item["problem_id"]
        problem_ids.add(pid)
        split_problems[item["split"]].add(pid)

print("Problem split:")
print(f"  Train problems: {len(split_problems['train'])}")
print(f"  Val problems  : {len(split_problems['val'])}")
print(f"  Test problems : {len(split_problems['test'])}")

print("\nCombined file written to:")
print(f"  {INPUT_FILE}")

# =====================================================
# STATS FUNCTION
# =====================================================
def print_stats(samples, title):
    print("\n" + "=" * 60)
    print(title)
    print("=" * 60)

    by_teacher = defaultdict(list)
    for s in samples:
        by_teacher[s["teacher"]].append(s)

    for teacher, items in by_teacher.items():
        print(f"\nTeacher: {teacher}")
        print(f"  Total samples: {len(items)}")

        split_counts = Counter(i["split"] for i in items)
        print(f"  Split distribution: {dict(split_counts)}")

        lang_counts = Counter(i["input_language"] for i in items)
        print(f"  Language distribution: {dict(lang_counts)}")

        score_counts = Counter(i["score"] for i in items)
        print(f"  Score distribution: {dict(score_counts)}")

# =====================================================
# OVERALL DATASET STATISTICS
# =====================================================
print_stats(samples, "OVERALL DATASET STATISTICS (AST-FIXED, score >= 1 only)")

# =====================================================
# PER-SPLIT STATISTICS
# =====================================================
for split in ["train", "val", "test"]:
    split_samples = [s for s in samples if s["split"] == split]
    print_stats(split_samples, f"{split.upper()} SPLIT STATISTICS")

import json
from collections import defaultdict

# =========================================
# CONFIG
# =========================================
INPUT_FILE = "/content/datasets/codenet_combined_translator_dataset_astfixed.jsonl"

# =========================================
# LOAD TEST SET ONLY
# =========================================
test_samples = []

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    for line in f:
        item = json.loads(line)
        if item["split"] == "test":
            test_samples.append(item)

print(f"Total test samples: {len(test_samples)}")

# =========================================
# AGGREGATE METRICS PER TEACHER
# =========================================
stats = defaultdict(lambda: {
    "total": 0,
    "parsable": 0,       # score >= 1
    "compilable": 0,     # score >= 2
    "functional": 0      # score == 3
})

for item in test_samples:
    teacher = item["teacher"]
    score = item["score"]

    stats[teacher]["total"] += 1

    if score >= 1:
        stats[teacher]["parsable"] += 1
    if score >= 2:
        stats[teacher]["compilable"] += 1
    if score == 3:
        stats[teacher]["functional"] += 1

# =========================================
# PRINT RESULTS (CLEAN TABLE STYLE)
# =========================================
print("\n" + "=" * 70)
print("TEACHER PERFORMANCE ON TEST SET")
print("=" * 70)

for teacher, s in stats.items():
    total = s["total"]

    p_cnt = s["parsable"]
    c_cnt = s["compilable"]
    f_cnt = s["functional"]

    p_pct = 100.0 * p_cnt / total if total > 0 else 0.0
    c_pct = 100.0 * c_cnt / total if total > 0 else 0.0
    f_pct = 100.0 * f_cnt / total if total > 0 else 0.0

    print(f"\nTeacher: {teacher}")
    print(f"  Total samples      : {total}")
    print(f"  Parsable (≥1)      : {p_cnt} ({p_pct:.2f}%)")
    print(f"  Compilable (≥2)    : {c_cnt} ({c_pct:.2f}%)")
    print(f"  Functional (=3)    : {f_cnt} ({f_pct:.2f}%)")

import json
from collections import defaultdict

# =========================================
# CONFIG
# =========================================
INPUT_FILE = "/content/datasets/codenet_combined_translator_dataset_astfixed.jsonl"

# =========================================
# LOAD TEST SET ONLY
# =========================================
test_samples = []

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    for line in f:
        item = json.loads(line)
        if item["split"] == "test":
            test_samples.append(item)

print(f"Total test samples: {len(test_samples)}")

# =========================================
# AGGREGATE METRICS
# teacher -> language -> stats
# =========================================
stats = defaultdict(lambda: defaultdict(lambda: {
    "total": 0,
    "parsable": 0,
    "compilable": 0,
    "functional": 0
}))

for item in test_samples:
    teacher = item["teacher"]
    lang = item["input_language"]
    score = item["score"]

    s = stats[teacher][lang]
    s["total"] += 1

    if score >= 1:
        s["parsable"] += 1
    if score >= 2:
        s["compilable"] += 1
    if score == 3:
        s["functional"] += 1

# =========================================
# PRINT RESULTS
# =========================================
print("\n" + "=" * 80)
print("TEACHER PERFORMANCE ON TEST SET — PER LANGUAGE")
print("=" * 80)

for teacher in sorted(stats.keys()):
    print(f"\nTeacher: {teacher}")
    print("-" * 80)

    # header
    print(
        f"{'Language':<10} "
        f"{'Total':>6} "
        f"{'Parsable':>12} "
        f"{'Compilable':>14} "
        f"{'Functional':>14}"
    )

    for lang in sorted(stats[teacher].keys()):
        s = stats[teacher][lang]
        total = s["total"]

        p = s["parsable"]
        c = s["compilable"]
        f = s["functional"]

        p_pct = 100.0 * p / total if total else 0.0
        c_pct = 100.0 * c / total if total else 0.0
        f_pct = 100.0 * f / total if total else 0.0

        print(
            f"{lang:<10} "
            f"{total:>6} "
            f"{p:>4} ({p_pct:>6.2f}%) "
            f"{c:>4} ({c_pct:>6.2f}%) "
            f"{f:>4} ({f_pct:>6.2f}%)"
        )