# -*- coding: utf-8 -*-
"""QwenCoderQS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQDNpl6P_Aqjcv7zyHqP8Yxx5W9Uf5ha

# QwenCoder - Quality-Stratification of DeepseekCoder Translations
"""

!apt-get update
!apt-get install -y g++ clang

import json
import random

FILE_PATH = "/content/datasets/codenet_single_solution_qwencoder.jsonl"
NUM_SAMPLES = 5

with open(FILE_PATH, "r", encoding="utf-8") as f:
    lines = f.readlines()

samples = random.sample(lines, min(NUM_SAMPLES, len(lines)))

for i, line in enumerate(samples, 1):
    data = json.loads(line.strip())
    print(f"\n--- Random Instance {i} ---")
    print(json.dumps(data, indent=2, ensure_ascii=False))

import json
import re
from tqdm import tqdm

INPUT_JSONL  = "/content/datasets/codenet_single_solution_qwencoder.jsonl"
OUTPUT_JSONL = "/content/datasets/codenet_single_solution_qwencoder_clean.jsonl"

# --------------------------------------------------
# Strong NON-Java signals (very conservative)
# --------------------------------------------------
NON_JAVA_PATTERNS = [
    r"#include\s*<",        # C / C++
    r"\bscanf\s*\(",
    r"\bprintf\s*\(",
    r"\busing\s+namespace\b",
    r"\bdef\s+\w+\s*\(",   # Python / Ruby
    r"\bputs\s*\(",
    r"\bprint\s+[^\(]",
    r"\bConsole\.Write",   # C#
    r"\bnamespace\s+\w+",
    r"\busing\s+System\b",
    r"\bend\b",            # Ruby
]

NON_JAVA_REGEX = re.compile("|".join(NON_JAVA_PATTERNS), re.IGNORECASE)


# --------------------------------------------------
# Java-positive signals (VERY relaxed)
# --------------------------------------------------
JAVA_POSITIVE_PATTERNS = [
    r"\bclass\s+\w+",
    r"\bpublic\s+class\b",
    r"\bpublic\s+static\b",
    r"\bSystem\.out\b",
    r"\bnew\s+\w+",
    r";",                  # Java almost always has semicolons
]

JAVA_POSITIVE_REGEX = re.compile("|".join(JAVA_POSITIVE_PATTERNS))


# --------------------------------------------------
# Remove markdown / explanations
# --------------------------------------------------
def extract_java_block(text: str) -> str:
    """
    Extract Java code from markdown blocks if present.
    Otherwise return raw text.
    """
    if not text:
        return ""

    # Prefer ```java blocks
    m = re.findall(r"```java\s*(.*?)```", text, re.DOTALL | re.IGNORECASE)
    if m:
        return m[0].strip()

    # Otherwise remove generic ``` blocks
    text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)

    return text.strip()


# --------------------------------------------------
# Core cleaner
# --------------------------------------------------
def clean_qwen_translation(raw: str) -> str | None:
    if not raw or not raw.strip():
        return None

    code = extract_java_block(raw)

    if not code or len(code.strip()) < 5:
        return None

    # Drop if clearly another language
    if NON_JAVA_REGEX.search(code):
        return None

    # Keep if it smells like Java
    if JAVA_POSITIVE_REGEX.search(code):
        return code.strip()

    # Otherwise: too ambiguous → drop
    return None


# --------------------------------------------------
# Main
# --------------------------------------------------
kept = 0
dropped = 0

with open(INPUT_JSONL, "r", encoding="utf-8") as fin, \
     open(OUTPUT_JSONL, "w", encoding="utf-8") as fout:

    for line in tqdm(fin, desc="Cleaning Qwen-Coder"):
        obj = json.loads(line)

        raw = obj.get("qwencoder_translation_raw")
        cleaned = clean_qwen_translation(raw)

        if cleaned is None:
            dropped += 1
            continue

        obj["qwencoder_translation_clean"] = cleaned
        fout.write(json.dumps(obj, ensure_ascii=False) + "\n")
        kept += 1

print("\n====================================")
print("Qwen-Coder Cleaning Complete")
print("====================================")
print(f"Kept   : {kept}")
print(f"Dropped: {dropped}")

import json
import subprocess
import tempfile
import os
import shutil

# =========================
# CONFIG
# =========================

QWEN_FILE = "/content/datasets/codenet_single_solution_qwencoder_clean.jsonl"
PROBLEM_TESTS_FILE = "/content/datasets/problem_tests.json"
OUTPUT_JSONL = "/content/datasets/codenet_single_solution_qwencoder_scored.jsonl"

EXEC_TIMEOUT = 5  # seconds
PROGRESS_INTERVAL = 10

# =========================
# COUNT TOTAL INSTANCES
# =========================

def count_jsonl_lines(path):
    with open(path, "r", encoding="utf-8") as f:
        return sum(1 for _ in f)

TOTAL_INSTANCES = count_jsonl_lines(QWEN_FILE)
print(f"Total instances in file : {TOTAL_INSTANCES}")

# =========================
# LOAD TEST CASES
# =========================

def load_tests(path):
    tests = {}
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
        for item in data:
            pid = item["problem_id"]
            if pid not in tests:
                tests[pid] = {
                    "input": item["input"],
                    "output": item["output"].strip()
                }
    return tests

PROBLEM_TESTS = load_tests(PROBLEM_TESTS_FILE)

# =========================
# JAVA COMPILE / RUN
# =========================

def java_compiles(code):
    tmpdir = tempfile.mkdtemp()
    java_file = os.path.join(tmpdir, "Main.java")

    with open(java_file, "w", encoding="utf-8") as f:
        f.write(code)

    compile_proc = subprocess.run(
        ["javac", java_file],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    if compile_proc.returncode != 0:
        shutil.rmtree(tmpdir)
        return False, None

    return True, tmpdir


def run_java(tmpdir, test_input):
    try:
        result = subprocess.run(
            ["java", "-cp", tmpdir, "Main"],
            input=test_input,
            text=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=EXEC_TIMEOUT
        )
        return result.stdout.strip()
    except Exception:
        return None

# =========================
# EVALUATION
# =========================

def evaluate_qwencoder():
    stats = {
        "total": 0,
        "score_0": 0,
        "parsable": 0,
        "compilable": 0,
        "functional": 0
    }

    with open(QWEN_FILE, "r", encoding="utf-8") as fin, \
         open(OUTPUT_JSONL, "w", encoding="utf-8") as fout:

        for idx, line in enumerate(fin, start=1):
            item = json.loads(line)
            stats["total"] += 1

            problem_id = item.get("problem_id")
            java_code = item.get("qwencoder_translation_clean")

            score = 0

            # ---------- Already cleaned ----------
            if not java_code:
                stats["score_0"] += 1
                item["score"] = 0
                fout.write(json.dumps(item) + "\n")
                continue

            stats["parsable"] += 1
            score = 1

            # ---------- Test lookup ----------
            test = PROBLEM_TESTS.get(problem_id)
            if test is None:
                item["score"] = score
                fout.write(json.dumps(item) + "\n")
                continue

            # ---------- Compile ----------
            compilable, tmpdir = java_compiles(java_code)

            if not compilable:
                item["score"] = score
                fout.write(json.dumps(item) + "\n")
                continue

            stats["compilable"] += 1
            score = 2

            # ---------- Functional ----------
            output = run_java(tmpdir, test["input"])
            shutil.rmtree(tmpdir)

            if output == test["output"]:
                stats["functional"] += 1
                score = 3

            item["score"] = score
            fout.write(json.dumps(item) + "\n")

            # ---------- Progress ----------
            if idx % PROGRESS_INTERVAL == 0 or idx == TOTAL_INSTANCES:
                percent = (idx / TOTAL_INSTANCES) * 100
                print("\n----------------------------------------")
                print(f"Progress: {idx}/{TOTAL_INSTANCES} ({percent:.2f}%)")
                print(f"Score 0       : {stats['score_0']}")
                print(f"Parsable      : {stats['parsable']}")
                print(f"Compilable    : {stats['compilable']}")
                print(f"Functional    : {stats['functional']}")
                print("----------------------------------------")

    # =========================
    # FINAL REPORT
    # =========================

    t = stats["total"]

    print("\n==============================")
    print("FINAL Qwen-Coder Java Results")
    print("==============================")
    print(f"Total samples       : {t}")
    print(f"Score 0             : {stats['score_0']}")
    print(f"Parsable            : {stats['parsable']}")
    print(f"Compilable          : {stats['compilable']}")
    print(f"Functional          : {stats['functional']}")

    if t > 0:
        print("\nPercentages:")
        print(f"Score 0      : {stats['score_0']/t:.2%}")
        print(f"Parsable     : {stats['parsable']/t:.2%}")
        print(f"Compilable   : {stats['compilable']/t:.2%}")
        print(f"Functional   : {stats['functional']/t:.2%}")

    print(f"\nScored file written to:\n{OUTPUT_JSONL}")

    return stats

# =========================
# RUN
# =========================

if __name__ == "__main__":
    evaluate_qwencoder()

import json
from collections import defaultdict

# =========================
# CONFIG
# =========================

SCORED_FILE = "/content/datasets/codenet_single_solution_qwencoder_scored.jsonl"

# =========================
# DATA STRUCTURE
# =========================

stats = defaultdict(lambda: {
    "total": 0,
    "score_0": 0,
    "parsable": 0,
    "compilable": 0,
    "functional": 0
})

# =========================
# READ & AGGREGATE
# =========================

with open(SCORED_FILE, "r", encoding="utf-8") as f:
    for line in f:
        item = json.loads(line)

        lang = item.get("input_language", "UNKNOWN")
        score = item.get("score", 0)

        s = stats[lang]
        s["total"] += 1

        if score == 0:
            s["score_0"] += 1
        if score >= 1:
            s["parsable"] += 1
        if score >= 2:
            s["compilable"] += 1
        if score == 3:
            s["functional"] += 1

# =========================
# PRINT SUMMARY
# =========================

print("\n==============================================")
print(" DeepSeek-Coder – Per Input Language Summary")
print("==============================================")

for lang in sorted(stats.keys()):
    s = stats[lang]
    t = s["total"]

    print(f"\nLanguage: {lang}")
    print("-" * (10 + len(lang)))
    print(f"Total samples   : {t}")
    print(f"Score 0         : {s['score_0']} ({s['score_0']/t:.2%})")
    print(f"Parsable (≥1)   : {s['parsable']} ({s['parsable']/t:.2%})")
    print(f"Compilable (≥2) : {s['compilable']} ({s['compilable']/t:.2%})")
    print(f"Functional (=3) : {s['functional']} ({s['functional']/t:.2%})")

# =========================
# OPTIONAL: SORT BY FUNCTIONAL RATE
# =========================

print("\n==============================================")
print(" Languages Sorted by Functional Accuracy")
print("==============================================")

ranked = sorted(
    stats.items(),
    key=lambda x: (x[1]["functional"] / x[1]["total"]) if x[1]["total"] > 0 else 0,
    reverse=True
)

for lang, s in ranked:
    rate = s["functional"] / s["total"] if s["total"] > 0 else 0
    print(f"{lang:12s} : {rate:.2%}  ({s['functional']}/{s['total']})")